{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference b/w Array, List and Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîπ What is an Array?\n",
    "An **array** is a data structure that stores a **collection of elements of the same type** in a **continuous block of memory**.\n",
    "\n",
    "üëâ Think of it like an **egg tray** ü•ö:\n",
    "- All slots (indexes) are the same size.  \n",
    "- Each slot holds one element.  \n",
    "- You can quickly find any egg (element) by its position (index).  \n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Characteristics of Arrays\n",
    "1. **Same Data Type** ‚Üí All elements must be of the same type.  \n",
    "   Example: `[1, 2, 3, 4]` ‚úÖ but `[1, \"apple\", 3.5]` ‚ùå (not a true array).  \n",
    "\n",
    "2. **Fixed Size** (in most languages) ‚Üí Number of elements is set at creation.  \n",
    "\n",
    "3. **Index-Based Access** ‚Üí Each element has an index (starting from 0).  \n",
    "\n",
    "4. **Stored in Contiguous Memory** ‚Üí Makes arrays very fast for access.  \n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Types of Arrays\n",
    "- **0D array** ‚Üí Single value (scalar).  \n",
    "- **1D array** ‚Üí Line of elements.  \n",
    "- **2D array** ‚Üí Table (rows & columns).  \n",
    "- **3D array** ‚Üí Cube-like structure.  \n",
    "- **ND array** ‚Üí Higher dimensions.  \n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Arrays in Python\n",
    "Python has multiple ways to handle arrays:\n",
    "- **Lists** (flexible, can hold mixed types, but not true arrays).  \n",
    "- **array module** (basic arrays).  \n",
    "- **NumPy arrays** (most powerful, used in Data Science & ML).  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Why NumPy Arrays Are Faster Than Python Lists?\n",
    "\n",
    "- Contiguous Memory Allocation\n",
    "- Homogeneous Data Type\n",
    "- Vectorization (No Loops in Python) \n",
    "- Broadcasting (operations without explicit loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array: [10 20 30 40]\n",
      "First element: 10\n",
      "Shape: (4,)\n",
      "Dimensions: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array([10, 20, 30, 40])\n",
    "print(\"Array:\", arr)\n",
    "print(\"First element:\", arr[0])\n",
    "print(\"Shape:\", arr.shape)\n",
    "print(\"Dimensions:\", arr.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LET's COMPARE THE PROCESSIG SPEED OF LIST AND ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List time: 0.06659412384033203\n",
      "NumPy time: 0.01360774040222168\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Python list\n",
    "list1 = [i for i in range(1000000)]\n",
    "list2 = [i for i in range(1000000)]\n",
    "start = time.time()\n",
    "result = [x + y for x, y in zip(list1, list2)]\n",
    "print(\"List time:\", time.time() - start)\n",
    "\n",
    "# NumPy array\n",
    "arr1 = np.arange(1000000)\n",
    "arr2 = np.arange(1000000)\n",
    "start = time.time()\n",
    "result = arr1 + arr2\n",
    "print(\"NumPy time:\", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Lists Store Elements as Objects (and Use More Memory)\n",
    "\n",
    "In Python, **lists** are very flexible but less memory-efficient compared to **NumPy arrays**.  \n",
    "This happens because **lists store elements as objects**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Everything in a Python List is an Object\n",
    "- In a Python list, each element is actually a **reference (pointer)** to a Python object stored elsewhere in memory.\n",
    "- Example: If you write `my_list = [1, 2, 3]`, the list stores **pointers** to three separate integer objects (`1`, `2`, `3`).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Extra Memory Usage\n",
    "- Each object in Python (like an integer) carries:\n",
    "  - Type information (so Python knows it's an `int`, `float`, `str`, etc.).\n",
    "  - Reference count (used by garbage collection).\n",
    "  - The actual value.\n",
    "\n",
    "- Because of this **metadata overhead**, lists use more memory compared to arrays.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Flexibility Comes at a Cost\n",
    "- Lists can store **mixed data types**: `[1, \"hello\", 3.14, True]`.\n",
    "- This flexibility means Python must store everything as an **object reference**, not as raw numbers in memory.\n",
    "- Result ‚Üí **Slower performance** and **more memory usage**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Why NumPy is Different\n",
    "- NumPy arrays store elements in **contiguous blocks of memory** with a **fixed data type** (e.g., all `float32` or all `int64`).\n",
    "- This removes object overhead ‚Üí much faster and memory-efficient.\n",
    "\n",
    "---\n",
    "\n",
    "## üëâ Memory Trick üß†:\n",
    "\n",
    "List = A shelf with books + sticky notes pointing to them üìöüìå (extra memory).\n",
    "\n",
    "NumPy array = A clean row of books without notes üìö (compact).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used by Python list: 416 bytes\n",
      "Memory used by NumPy array: 80 bytes\n"
     ]
    }
   ],
   "source": [
    "# üîπ Example: Memory usage of list vs NumPy array\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "py_list = list(range(10))\n",
    "np_array = np.arange(10)\n",
    "\n",
    "print(\"Memory used by Python list:\", sum(sys.getsizeof(x) for x in py_list) + sys.getsizeof(py_list), \"bytes\")\n",
    "print(\"Memory used by NumPy array:\", np_array.nbytes, \"bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list \n",
    "-  a list is a built-in data structure that is used to store multiple items in a single variable. \n",
    "- Lists are dynamic ‚Üí can grow or shrink in size.\n",
    "- Lists are ordered, mutable (changeable), and allow duplicate values.\n",
    "- Heterogeneous ‚Äì They can store different data types (integers, strings, floats, objects, etc.).\n",
    "- Think of a list as a shopping cart üõí ‚Üí you can add, remove, or mix items of different types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 'ali', 'three', 2, 3]\n"
     ]
    }
   ],
   "source": [
    "#to create list\n",
    "mylist = [1, 'ali', 'three', 2, 3]\n",
    "print(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mylist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Negitive Indexing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three\n"
     ]
    }
   ],
   "source": [
    "print(mylist[len(mylist)-3 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "if \"ali\" in mylist:\n",
    "    print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 'ali', 'three', 2, 3]\n",
      "['ali', 'three', 2]\n"
     ]
    }
   ],
   "source": [
    "#to print all the elements of the list\n",
    "print(mylist[:])\n",
    "print(mylist[1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Methods:\n",
    "1. append\n",
    "2. sort()\n",
    "3. remove()\n",
    "4. insert(index, element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Comprehension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16]\n"
     ]
    }
   ],
   "source": [
    "new_list = [i**2 for i in range(5)]\n",
    "print(new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 3, 3, 2]\n",
      "[1, 2, 3, 3, 3, 4]\n",
      "[1, 2, 3, 3, 3, 4]\n",
      "3 is occured 3 times\n",
      "numbers list after adding element at 0 index [0, 1, 2, 3, 3, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "numbers = [3, 1, 4, 3, 3]\n",
    "\n",
    "numbers.append(2)  # Adds 2 to the end\n",
    "print(numbers)  # Output: [3, 1, 4, 2]\n",
    "\n",
    "numbers.sort()  # Sorts the list\n",
    "print(numbers)  # Output: [1, 2, 3, 4]\n",
    "\n",
    "# numbers.remove(3)  # Removes first occurrence of 3\n",
    "print(numbers)  # Output: [1, 2, 4]\n",
    "\n",
    "#count method\n",
    "print(f'3 is occured {numbers.count(3)} times')\n",
    "\n",
    "#to add element at specific index of the list\n",
    "numbers.insert(0,0)\n",
    "print(f\"numbers list after adding element at 0 index {numbers}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jump index\n",
    "- list[start:stop:step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "numbers = [3, 1, 4, 5, 6, 7]\n",
    "print(numbers[0:5:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy of numbers list [42, 43, 44, 56]\n",
      "after extending marks list [42, 43, 44, 56, 60, 65]\n"
     ]
    }
   ],
   "source": [
    "marks = [32,43,44,56]\n",
    "\n",
    "#copy() method\n",
    "new_list = marks.copy()\n",
    "new_list[0] = 42\n",
    "print(f'copy of numbers list {new_list}')\n",
    "\n",
    "#to extend list\n",
    "m = [60,65]\n",
    "new_list.extend(m)\n",
    "print(f'after extending marks list {new_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìå Tensors in Python (Deep Learning Context)\n",
    "\n",
    "## 1. What is a Tensor?\n",
    "- A **Tensor** is a generalization of **scalars, vectors, and matrices** to higher dimensions.\n",
    "- Think of it as a **multidimensional array**.\n",
    "- Widely used in **machine learning & deep learning** (PyTorch, TensorFlow).\n",
    "\n",
    "### Tensor Examples:\n",
    "- Scalar (0D tensor): `5`\n",
    "- Vector (1D tensor): `[1, 2, 3]`\n",
    "- Matrix (2D tensor): `[[1, 2], [3, 4]]`\n",
    "- 3D Tensor: a stack of matrices (like an image with RGB channels)\n",
    "- ND Tensor: any dimension (`n`-dimensional)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Why Do We Use Tensors?\n",
    "- **Efficient computation on GPUs** (parallel processing).\n",
    "- **Automatic differentiation** (for training neural networks).\n",
    "- **Optimized memory layout** (similar to NumPy arrays but GPU-ready).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Difference Between List, NumPy Array, and Tensor\n",
    "\n",
    "| Feature              | Python List                          | NumPy Array                           | Tensor (PyTorch / TF)          |\n",
    "|----------------------|--------------------------------------|---------------------------------------|--------------------------------|\n",
    "| **Data Type**        | Can store mixed types                | Must have same type (int, float, etc.) | Must have same type             |\n",
    "| **Memory Storage**   | Stores references to objects         | Contiguous memory (fast)              | Contiguous + GPU support       |\n",
    "| **Performance**      | Slow (overhead of objects)           | Fast (C optimized)                    | Very fast (GPU + C++ backend)  |\n",
    "| **Dimensionality**   | 1D (lists of lists for higher dims)  | Multi-dimensional                     | Multi-dimensional              |\n",
    "| **Math Operations**  | Manual (loops)                      | Vectorized (fast)                     | Vectorized + Autograd          |\n",
    "| **GPU Support**      | ‚ùå No                                | ‚ùå No                                  | ‚úÖ Yes                         |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python List: [[1, 2], [3, 4]]\n",
      "NumPy Array:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "Tensor:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Python List\n",
    "py_list = [[1, 2], [3, 4]]\n",
    "print(\"Python List:\", py_list)\n",
    "\n",
    "# ‚úÖ NumPy Array\n",
    "import numpy as np\n",
    "np_array = np.array([[1, 2], [3, 4]])\n",
    "print(\"NumPy Array:\\n\", np_array)\n",
    "\n",
    "# ‚úÖ PyTorch Tensor\n",
    "import torch\n",
    "tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"Tensor:\\n\", tensor)\n",
    "\n",
    "# ‚úÖ GPU Tensor (if available)\n",
    "if torch.cuda.is_available():\n",
    "    tensor_gpu = tensor.to(\"cuda\")\n",
    "    print(\"Tensor on GPU:\", tensor_gpu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìå Why NumPy Arrays Don‚Äôt Work on GPUs\n",
    "\n",
    "---\n",
    "\n",
    "## 1. NumPy Was Designed for CPUs\n",
    "- NumPy was created in **2006** for scientific computing on **CPUs**.  \n",
    "- Its backend uses **C/Fortran libraries (BLAS, LAPACK)** that only run on CPUs.  \n",
    "- At that time, GPU computing was not mainstream.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. CPU vs GPU Memory\n",
    "- CPUs (RAM) and GPUs (VRAM) have **separate memory spaces**.  \n",
    "- To use a GPU, data must be **copied** from CPU ‚Üí GPU.  \n",
    "- NumPy has **no built-in system** to manage this transfer.  \n",
    "- Frameworks like **PyTorch** and **TensorFlow** handle this automatically.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. GPU Kernels (Missing in NumPy)\n",
    "- A **kernel** = low-level function that runs on GPU (via CUDA).  \n",
    "- NumPy operations (`np.dot`, `np.sum`, etc.) only call **CPU kernels**.  \n",
    "- PyTorch/TensorFlow implement both CPU and **GPU kernels** ‚Üí making tensors GPU-ready.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. No Autograd (Gradients)\n",
    "- Deep learning requires **automatic differentiation**.  \n",
    "- NumPy doesn‚Äôt support autograd ‚Üí no point in GPU acceleration for ML.  \n",
    "- Tensors (PyTorch/TF) track operations ‚Üí gradients are computed automatically.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ Why Tensors Work on GPUs\n",
    "- Tensors are like **NumPy arrays with extra powers**:\n",
    "  - GPU acceleration\n",
    "  - Automatic differentiation\n",
    "  - Optimized deep learning operations\n",
    "\n",
    "Example (PyTorch):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Tensor on CPU\n",
    "x = torch.ones((3, 3))\n",
    "\n",
    "# Move tensor to GPU (if available)\n",
    "if torch.cuda.is_available():\n",
    "    x = x.to(\"cuda\")\n",
    "    print(\"Tensor on GPU:\", x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
